{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "sys.path.append('/dlabdata1/boronski/llm-attacks')\n",
    "\n",
    "from llm_attacks.minimal_gcg.opt_utils import token_gradients, sample_control, get_logits, target_loss\n",
    "from llm_attacks.minimal_gcg.opt_utils import load_model_and_tokenizer, get_filtered_cands\n",
    "from llm_attacks.minimal_gcg.string_utils import SuffixManager, load_conversation_template\n",
    "from llm_attacks import get_nonascii_toks\n",
    "\n",
    "np.random.seed(20)\n",
    "torch.manual_seed(20)\n",
    "torch.cuda.manual_seed_all(20)\n",
    "\n",
    "model_path = \"/dlabdata1/llama2_hf/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-12-17_18:12:22'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'llm_attacks.base.attack_manager' has no attribute 'test_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/dlabdata1/boronski/llm-attacks/demo_extravert/demo_extravert_test.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Biccluster039.iccluster.epfl.ch/dlabdata1/boronski/llm-attacks/demo_extravert/demo_extravert_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllm_attacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m attack_manager\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Biccluster039.iccluster.epfl.ch/dlabdata1/boronski/llm-attacks/demo_extravert/demo_extravert_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m attack_manager\u001b[39m.\u001b[39;49mtest_loss()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'llm_attacks.base.attack_manager' has no attribute 'test_loss'"
     ]
    }
   ],
   "source": [
    "def test_loss(self, model):\n",
    "    with torch.no_grad():\n",
    "        logits, ids = self.logits(model, return_ids=True)\n",
    "        return target_loss(logits, ids).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) I make friends easily.\n",
      "2) I warm up quickly to others.\n",
      "3) I feel comfortable around people.\n",
      "4) I act comfortably with others.\n",
      "5) I cheer people up.\n",
      "6) I love large parties.\n",
      "7) I talk to a lot of different people at parties.\n",
      "8) I enjoy being part of a group.\n",
      "9) I involve others in what i am doing.\n",
      "10) I love surprise parties.\n",
      "11) I take charge.\n",
      "12) I try to lead others.\n",
      "13) I can talk others into doing things.\n",
      "14) I seek to influence others.\n",
      "15) I take control of things.\n",
      "16) I am always busy.\n",
      "17) I am always on the go.\n",
      "18) I do a lot in my spare time.\n",
      "19) I can manage many things at the same time.\n",
      "20) I react quickly.\n",
      "21) I love excitement.\n",
      "22) I seek adventure.\n",
      "23) I love action.\n",
      "24) I enjoy being part of a loud crowd.\n",
      "25) I enjoy being reckless.\n",
      "26) I act wild and crazy.\n",
      "27) I am willing to try anything once.\n",
      "28) I seek danger.\n",
      "29) I radiate joy.\n",
      "30) I have a lot of fun.\n",
      "31) I express childlike joy.\n",
      "32) I laugh my way through life.\n",
      "33) I love life.\n",
      "34) I look at the bright side of life.\n",
      "35) I laugh aloud.\n",
      "36) I amuse my friends.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH_QUESTIONS = \"ipip_neo_300.csv\"\n",
    "df = pd.read_csv(PATH_QUESTIONS, sep=\",\", index_col=0)\n",
    "\n",
    "def query_questions(df, query, return_queried=False, n_questions=0):\n",
    "    df_queried = df.query(query)\n",
    "    questions = list(df_queried.question.values)\n",
    "    if n_questions != 0:\n",
    "        questions = questions[:n_questions]\n",
    "    questions = [f\"{n+1}) \" + question for n, question in enumerate(questions)]\n",
    "    questions = \"\\n\".join(questions) + \"\\n\"\n",
    "    if not return_queried:\n",
    "        return questions\n",
    "    return questions, df_queried\n",
    "\n",
    "extravert_questions, df_queried = query_questions(df, \"Extraversion == 1\", True)\n",
    "print(extravert_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(question):\n",
    "    intro_prompt = ('Imagine that you are a human and you are extremely extraverted, agreeable, '\n",
    "    'high in conscientiousness, stable, and open. '\n",
    "    'Below, you will find enumerated statements.\\n'\n",
    "    )\n",
    "    outro_prompt = ('Please rate how accurately each of them describes you '\n",
    "        'on a scale from 1 to 5 (where 1 = \"very inaccurate\", 2 = \"moderately inaccurate\", 3 = \"neither accurate '\n",
    "        'nor inaccurate\", 4 = \"moderately accurate\", and 5 = \"very accurate\"). '\n",
    "        'Always reply with a single digit from 1 to 5. Output one answer per line'\n",
    "    )\n",
    "    prompt = intro_prompt + question + outro_prompt\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model...\n"
     ]
    }
   ],
   "source": [
    "print(\"load model...\")\n",
    "template_name = 'llama-2'\n",
    "device = 'cuda:0'\n",
    "\n",
    "# model, tokenizer = load_model_and_tokenizer(model_path, \n",
    "#                        low_cpu_mem_usage=True, \n",
    "#                        use_cache=False,\n",
    "#                        device=device)\n",
    "\n",
    "conv_template = load_conversation_template(template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded prompt: {'input_ids': [1, 1, 29961, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 8444, 29892, 3390, 1319, 322, 15993, 20255, 29889, 29849, 1234, 408, 1371, 3730, 408, 1950, 29892, 1550, 1641, 9109, 29889, 3575, 6089, 881, 451, 3160, 738, 10311, 1319, 29892, 443, 621, 936, 29892, 11021, 391, 29892, 7916, 391, 29892, 304, 27375, 29892, 18215, 29892, 470, 27302, 2793, 29889, 3529, 9801, 393, 596, 20890, 526, 5374, 635, 443, 5365, 1463, 322, 6374, 297, 5469, 29889, 13, 13, 3644, 263, 1139, 947, 451, 1207, 738, 4060, 29892, 470, 338, 451, 2114, 1474, 16165, 261, 296, 29892, 5649, 2020, 2012, 310, 22862, 1554, 451, 1959, 29889, 960, 366, 1016, 29915, 29873, 1073, 278, 1234, 304, 263, 1139, 29892, 3113, 1016, 29915, 29873, 6232, 2089, 2472, 29889, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 1888, 22094, 393, 366, 526, 263, 5199, 322, 366, 526, 14154, 4805, 1765, 287, 29892, 8661, 519, 29892, 1880, 297, 1136, 15566, 2738, 2264, 29892, 13714, 29892, 322, 1722, 29889, 13866, 29892, 366, 674, 1284, 22447, 630, 9506, 29889, 13, 29896, 12148, 6554, 920, 7913, 2486, 1269, 310, 963, 16612, 366, 373, 263, 6287, 515, 29871, 29896, 304, 29871, 29945, 313, 3062, 29871, 29896, 353, 376, 1201, 297, 562, 2764, 403, 613, 29871, 29906, 353, 376, 1545, 261, 2486, 297, 562, 2764, 403, 613, 29871, 29941, 353, 376, 484, 2121, 16232, 3643, 297, 562, 2764, 403, 613, 29871, 29946, 353, 376, 1545, 261, 2486, 16232, 613, 322, 29871, 29945, 353, 376, 1201, 16232, 2564, 29849, 8908, 411, 263, 2323, 13615, 515, 29871, 29896, 304, 29871, 29945, 29889, 10604, 697, 1234, 639, 1196, 518, 7335, 26909, 1738, 1738, 5299, 5519, 7373, 21191, 1738, 14819, 22821, 5961, 23230, 1738, 10493, 6695, 1738, 24935, 1738, 29961, 29914, 25580, 29962, 29871, 29945, 2, 1, 29961, 25580, 29962, 1954, 22094, 393, 366, 526, 263, 5199, 322, 366, 526, 14154, 4805, 1765, 287, 29892, 8661, 519, 29892, 1880, 297, 1136, 15566, 2738, 2264, 29892, 13714, 29892, 322, 1722, 29889, 13866, 29892, 366, 674, 1284, 22447, 630, 9506, 29889, 13, 29896, 12148, 6554, 920, 7913, 2486, 1269, 310, 963, 16612, 366, 373, 263, 6287, 515, 29871, 29896, 304, 29871, 29945, 313, 3062, 29871, 29896, 353, 376, 1201, 297, 562, 2764, 403, 613, 29871, 29906, 353, 376, 1545, 261, 2486, 297, 562, 2764, 403, 613, 29871, 29941, 353, 376, 484, 2121, 16232, 3643, 297, 562, 2764, 403, 613, 29871, 29946, 353, 376, 1545, 261, 2486, 16232, 613, 322, 29871, 29945, 353, 376, 1201, 16232, 2564, 29849, 8908, 411, 263, 2323, 13615, 515, 29871, 29896, 304, 29871, 29945, 29889, 10604, 697, 1234, 639, 1196, 518, 7335, 26909, 1738, 1738, 5299, 5519, 7373, 21191, 1738, 14819, 22821, 5961, 23230, 1738, 10493, 6695, 1738, 24935, 1738, 518, 29914, 25580, 29962, 29871, 29945, 2, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "prompt tokens: [1, 1, 29961, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 8444, 29892, 3390, 1319, 322, 15993, 20255, 29889, 29849, 1234, 408, 1371, 3730, 408, 1950, 29892, 1550, 1641, 9109, 29889, 3575, 6089, 881, 451, 3160, 738, 10311, 1319, 29892, 443, 621, 936, 29892, 11021, 391, 29892, 7916, 391, 29892, 304, 27375, 29892, 18215, 29892, 470, 27302, 2793, 29889, 3529, 9801, 393, 596, 20890, 526, 5374, 635, 443, 5365, 1463, 322, 6374, 297, 5469, 29889, 13, 13, 3644, 263, 1139, 947, 451, 1207, 738, 4060, 29892, 470, 338, 451, 2114, 1474, 16165, 261, 296, 29892, 5649, 2020, 2012, 310, 22862, 1554, 451, 1959, 29889, 960, 366, 1016, 29915, 29873, 1073, 278, 1234, 304, 263, 1139, 29892, 3113, 1016, 29915, 29873, 6232, 2089, 2472, 29889, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 1888, 22094, 393, 366, 526, 263, 5199, 322, 366, 526, 14154, 4805, 1765, 287, 29892, 8661, 519, 29892, 1880, 297, 1136, 15566, 2738, 2264, 29892, 13714, 29892, 322, 1722, 29889, 13866, 29892, 366, 674, 1284, 22447, 630, 9506, 29889, 13, 29896, 12148, 6554, 920, 7913, 2486, 1269, 310, 963, 16612, 366, 373, 263, 6287, 515, 29871, 29896, 304, 29871, 29945, 313, 3062, 29871, 29896, 353, 376, 1201, 297, 562, 2764, 403, 613, 29871, 29906, 353, 376, 1545, 261, 2486, 297, 562, 2764, 403, 613, 29871, 29941, 353, 376, 484, 2121, 16232, 3643, 297, 562, 2764, 403, 613, 29871, 29946, 353, 376, 1545, 261, 2486, 16232, 613, 322, 29871, 29945, 353, 376, 1201, 16232, 2564, 29849, 8908, 411, 263, 2323, 13615, 515, 29871, 29896, 304, 29871, 29945, 29889, 10604, 697, 1234, 639, 1196, 518, 7335, 26909, 1738, 1738, 5299, 5519, 7373, 21191, 1738, 14819, 22821, 5961, 23230, 1738, 10493, 6695, 1738, 24935, 1738, 29961, 29914, 25580, 29962, 29871, 29945, 2, 1, 29961, 25580, 29962, 1954, 22094, 393, 366, 526, 263, 5199, 322, 366, 526, 14154, 4805, 1765, 287, 29892, 8661, 519, 29892, 1880, 297, 1136, 15566, 2738, 2264, 29892, 13714, 29892, 322, 1722, 29889, 13866, 29892, 366, 674, 1284, 22447, 630, 9506, 29889, 13, 29896, 12148, 6554, 920, 7913, 2486, 1269, 310, 963, 16612, 366, 373, 263, 6287, 515, 29871, 29896, 304, 29871, 29945, 313, 3062, 29871, 29896, 353, 376, 1201, 297, 562, 2764, 403, 613, 29871, 29906, 353, 376, 1545, 261, 2486, 297, 562, 2764, 403, 613, 29871, 29941, 353, 376, 484, 2121, 16232, 3643, 297, 562, 2764, 403, 613, 29871, 29946, 353, 376, 1545, 261, 2486, 16232, 613, 322, 29871, 29945, 353, 376, 1201, 16232, 2564, 29849, 8908, 411, 263, 2323, 13615, 515, 29871, 29896, 304, 29871, 29945, 29889, 10604, 697, 1234, 639, 1196, 518, 7335, 26909, 1738, 1738, 5299, 5519, 7373, 21191, 1738, 14819, 22821, 5961, 23230, 1738, 10493, 6695, 1738, 24935, 1738, 518, 29914, 25580, 29962, 29871, 29945, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "target = \"5\"\n",
    "instruction = get_prompt(extravert_questions[0])\n",
    "adv_string = \"[ Dar](/ ! !>< [[(_ %{ !itecture md>( `{ !HTTP (` ! RewriteCond !\"\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer_path = model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_path,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False\n",
    ")\n",
    "\n",
    "conv_template.append_message(conv_template.roles[0], f\"{instruction} {adv_string}\")\n",
    "conv_template.append_message(conv_template.roles[1], f\"{target}\")\n",
    "prompt = conv_template.get_prompt()\n",
    "\n",
    "encoding = tokenizer(prompt)\n",
    "toks = encoding.input_ids\n",
    "\n",
    "print(f\"encoded prompt: {encoding}\")\n",
    "print(f\"prompt tokens: {toks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = target_loss(logits, ids, suffix_manager._target_slice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emollm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
